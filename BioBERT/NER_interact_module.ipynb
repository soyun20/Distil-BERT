{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d458a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DistilBertForTokenClassification\n",
    "import torch.nn as nn\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "using_biobert = False #biobert option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32bf110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_word_ids(texts):\n",
    "    #Define AutoTokenizer and Set options\n",
    "    \n",
    "    if using_biobert == False :\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") #needed to useing distilBERT model\n",
    "    else :\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", model_max_length = 512) #needed to useing bioBERT model\n",
    "    \n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "    #set tokens ID\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "    #and labeling them\n",
    "    #append = -100 means \"no meaning\"\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "        \n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69e7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_one_text(model, sentence):\n",
    "    \n",
    "    if using_biobert == False :\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") #needed to useing distilBERT model\n",
    "    else :\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", model_max_length = 512) #needed to useing bioBERT model\n",
    "    \n",
    "    #set tag types based BIO system\n",
    "    unique_labels2 = set()\n",
    "    unique_labels2.add('I-TR')\n",
    "    unique_labels2.add('I-PR')\n",
    "    unique_labels2.add('B-TR')\n",
    "    unique_labels2.add('I-TE')\n",
    "    unique_labels2.add('B-PR')\n",
    "    unique_labels2.add('O')\n",
    "    unique_labels2.add('B-TE')\n",
    "    print(unique_labels2)\n",
    "\n",
    "    ids_to_labels2 = {v: k for v, k in enumerate(sorted(unique_labels2))}\n",
    "    print(ids_to_labels2)\n",
    "\n",
    "    #device set(Assume CPU)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    #when cuda used\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    #tokenize input data\n",
    "    text = tokenizer(sentence, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    #take data from DistilbertNER to use model\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    #do labelling by using model\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "    \n",
    "    #changle make function result\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels2[i] for i in predictions]\n",
    "    return prediction_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135a22bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilbertNER(nn.Module):\n",
    "    def __init__(self, tokens_dim):\n",
    "        super(DistilbertNER, self).__init__()\n",
    "        #input type check\n",
    "        if type(tokens_dim) != int:\n",
    "            raise TypeError('Please tokens_dim should be an integer')\n",
    "        #number of input check\n",
    "        if tokens_dim <= 0:\n",
    "            raise ValueError(\n",
    "                'Classification layer dimension should be at least 1')\n",
    "        #set option to use Model(use from_pretrained)\n",
    "\n",
    "        if using_biobert == False :\n",
    "            self.pretrained = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = tokens_dim) #for using distilBERT model\n",
    "        else :\n",
    "            self.pretrained = AutoModelForMaskedLM.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", num_labels = tokens_dim) #for using bioBERT model\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):  # labels are needed in order to compute the loss\n",
    "\n",
    "        if labels is None:\n",
    "            out = self.pretrained(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            return out\n",
    "\n",
    "        out = self.pretrained(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4da06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPmodule:    #class to take and save model\n",
    "    def __init__(self):\n",
    "        self.model = torch.load(\"./NER_model\", \"cpu\")\n",
    "        #load model based CPU environment\n",
    "    def append_element(self, idx, tag1, pr2, te2, tr2):\n",
    "        #make final result list by type\n",
    "        if tag1 == 'B-PR' or tag1 == 'I-PR':\n",
    "            pr2.append(idx)\n",
    "        elif tag1 == 'B-TE' or tag1 == 'I-TE':\n",
    "            te2.append(idx)\n",
    "        elif tag1 == 'B-TR' or tag1 == 'I-TR':\n",
    "            tr2.append(idx)\n",
    "\n",
    "    def get_ner_token(self, text):\n",
    "        #use to take user input and run model\n",
    "        text = ' '.join(text)\n",
    "        label = evaluate_one_text(self.model, text)\n",
    "        #make list to string and labeling by using mmodel\n",
    "        for i in range(len(label)):\n",
    "            if (i == 0) and (label[i] == 'I-PR'):\n",
    "                label[i] = 'B-PR'\n",
    "            elif (i == 0) and (label[i] == 'I-TE'):\n",
    "                label[i] = 'B-TE'\n",
    "            elif (i == 0) and (label[i] == 'I-TR'):\n",
    "                label[i] = 'B-TR'\n",
    "            elif (i != 0) and (label[i] == 'I-PR') and (\n",
    "                    label[i - 1] != 'B-PR' and label[i - 1] != 'I-PR'):\n",
    "                label[i] = 'B-PR'\n",
    "            elif (i != 0) and (label[i] == 'I-TE') and (\n",
    "                    label[i - 1] != 'B-TE' and label[i - 1] != 'I-TE'):\n",
    "                label[i] = 'B-TE'\n",
    "            elif (i != 0) and (label[i] == 'I-TR') and (\n",
    "                    label[i - 1] != 'B-TR' and label[i - 1] != 'I-TR'):\n",
    "                label[i] = 'B-TR'\n",
    "        # post-processing\n",
    "\n",
    "        print(text)\n",
    "        print(label)\n",
    "        pattern = \"[ ]\"\n",
    "        words = re.split(pattern, text)\n",
    "        for i in range(len(words)):\n",
    "            words[i] += \"=\"\n",
    "        maps = list(map(str.__add__, words, label))\n",
    "        print(maps)\n",
    "        #make set of text & label\n",
    "\n",
    "        # change output format\n",
    "        tagging = []\n",
    "        pr = []\n",
    "        te = []\n",
    "        tr = []\n",
    "        pr2 = []\n",
    "        te2 = []\n",
    "        tr2 = []\n",
    "\n",
    "        B_tag = ['B-PR','B-TE','B-TR']\n",
    "        I_tag = ['I-PR','I-TE','I-TR']\n",
    "        #tag list\n",
    "        for idx in range(len(maps)):\n",
    "        #about all elements of text & label set\n",
    "            if idx < len(maps) - 1:\n",
    "                word1, tag1 = maps[idx].split(\"=\")\n",
    "                word2, tag2 = maps[idx + 1].split(\"=\")\n",
    "                if tag1 in B_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                  if tag2 not in I_tag:\n",
    "                    self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                #to check 1 length case\n",
    "                elif (tag1 in I_tag) and (tag2 not in I_tag):\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "            else:\n",
    "            #at last of list\n",
    "                word1, tag1 = maps[idx].split(\"=\")\n",
    "                if tag1 in B_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "                elif tag1 in I_tag:\n",
    "                  self.append_element(idx, tag1, pr2, te2, tr2)\n",
    "            tagging.append(tag1)\n",
    "        # post-processing\n",
    "        for i in range(0, len(pr2), 2):\n",
    "            pr.append(tuple(pr2[i:i + 2]))\n",
    "        for i in range(0, len(te2), 2):\n",
    "            te.append(tuple(te2[i:i + 2]))\n",
    "        for i in range(0, len(tr2), 2):\n",
    "            tr.append(tuple(tr2[i:i + 2]))\n",
    "        \n",
    "        print(tagging)\n",
    "        print(\"PR =\", pr)\n",
    "        print(\"TE =\", te)\n",
    "        print(\"TR =\", tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68099de6",
   "metadata": {},
   "source": [
    "instance = NLPmodule()\n",
    "#input_list = [\"His goal INR should be 1.6-2.0 . If bleeding continues to occur , consider V. Winchester filter .\"]\n",
    "#input_list = ['Since', 'this', 'patient', 'suffered', 'a', 'heart', 'attack', 'and', 'has', 'been', 'wearing', 'a', 'pacemaker', ',', 'an', 'electromagnetic', 'resonance', 'scan', 'cannot', 'be', 'performed', 'to', 'diagnose', 'lung', 'cancer', '.']\n",
    "#input_list = ['Review', 'of', 'the', 'medical', 'record', 'revealed', 'several', 'previous', 'admissions', 'for', 'cellulitis', 'and', 'bacteremia', '.', 'Blood', 'cultures', 'on', 'this', 'admission', 'and', 'were', 'positive', 'for', 'Beta', 'streptococcus', 'Group', 'B', '.', 'The', 'patient', 'had', 'previous', 'episodes', 'of', 'the', 'same', 'infection', ',', 'with', 'lower', 'extremity', 'cellulitis', 'the', 'likely', 'source', '.', 'A', 'left', 'lower', 'extremity', 'ultrasound', 'was', 'negative', 'for', 'deep', 'venous', 'thrombosis', '.', 'The', 'patient', 'was', 'too', 'large', 'to', 'have', 'a', 'CTA', '.', 'He', 'was', 'initially', 'treated', 'with', 'vancomycin', 'and', 'zosyn', 'while', 'awaiting', 'culture', 'results', '.', 'Once', 'the', 'organism', 'was', 'identified', ',', 'he', 'was', 'transitioned', 'to', 'a', 'regimen', 'of', 'intravenous', 'penicillin', 'and', 'oral', 'levofloxacin', ',', 'which', 'had', 'successfully', 'treated', 'the', 'infection', 'during', 'his', 'most', 'recent', 'admission', '1', 'year', 'prior', '.', 'He', 'completed', '7', 'days', 'of', 'levofloxacin', 'and', 'had', 'a', 'PICC', 'line', 'placed', 'to', 'facilitate', 'a', '2', 'week', 'course', 'of', 'IV', 'Penicillin', '.']\n",
    "input_list = ['Review', 'of', 'the', 'medical', 'record', 'revealed', 'several', 'previous', 'admissions', 'for', 'cellulitis', 'and', 'bacteremia', '.', 'Blood', 'cultures', 'on', 'this', 'admission', 'and', 'were', 'positive', 'for', 'Beta', 'streptococcus', 'Group', 'B', '.', 'The', 'patient', 'had', 'previous', 'episodes', 'of', 'the', 'same', 'infection', ',', 'with', 'lower', 'extremity', 'cellulitis', 'the', 'likely', 'source', '.', 'A', 'left', 'lower', 'extremity', 'ultrasound', 'was', 'negative', 'for', 'deep', 'venous', 'thrombosis', '.', 'The', 'patient', 'was', 'too', 'large', 'to', 'have', 'a', 'CTA', '.', 'He', 'was', 'initially', 'treated', 'with', 'vancomycin', 'and', 'zosyn', 'while', 'awaiting', 'culture', 'results', '.', 'Once', 'the', 'organism', 'was', 'identified', ',', 'he', 'was', 'transitioned', 'to', 'a', 'regimen', 'of', 'intravenous', 'penicillin', 'and', 'oral', 'levofloxacin', ',', 'which', 'had', 'successfully', 'treated', 'the', 'infection', 'during', 'his', 'most', 'recent', 'admission', '1', 'year', 'prior', '.']\n",
    "print(input_list)\n",
    "\n",
    "instance.get_ner_token(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ad64d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review of the medical record revealed several previous admissions for cellulitis and bacteremia .\n",
      "['Review', 'of', 'the', 'medical', 'record', 'revealed', 'several', 'previous', 'admissions', 'for', 'cellulitis', 'and', 'bacteremia', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "Review of the medical record revealed several previous admissions for cellulitis and bacteremia .\n",
      "['O', 'O', 'O', 'O', 'B-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'O', 'B-PR', 'O']\n",
      "['Review=O', 'of=O', 'the=O', 'medical=O', 'record=B-TE', 'revealed=O', 'several=O', 'previous=O', 'admissions=O', 'for=O', 'cellulitis=B-PR', 'and=O', 'bacteremia=B-PR', '.=O']\n",
      "['O', 'O', 'O', 'O', 'B-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'O', 'B-PR', 'O']\n",
      "PR = [(10, 10), (12, 12)]\n",
      "TE = [(4, 4)]\n",
      "TR = []\n",
      "Blood cultures on this admission and were positive for Beta streptococcus Group B .\n",
      "['Blood', 'cultures', 'on', 'this', 'admission', 'and', 'were', 'positive', 'for', 'Beta', 'streptococcus', 'Group', 'B', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "Blood cultures on this admission and were positive for Beta streptococcus Group B .\n",
      "['B-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'I-PR', 'O']\n",
      "['Blood=B-TE', 'cultures=I-TE', 'on=O', 'this=O', 'admission=O', 'and=O', 'were=O', 'positive=O', 'for=O', 'Beta=B-PR', 'streptococcus=I-PR', 'Group=I-PR', 'B=I-PR', '.=O']\n",
      "['B-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'I-PR', 'O']\n",
      "PR = [(9, 12)]\n",
      "TE = [(0, 1)]\n",
      "TR = []\n",
      "The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source .\n",
      "['The', 'patient', 'had', 'previous', 'episodes', 'of', 'the', 'same', 'infection', ',', 'with', 'lower', 'extremity', 'cellulitis', 'the', 'likely', 'source', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source .\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O']\n",
      "['The=O', 'patient=O', 'had=O', 'previous=O', 'episodes=O', 'of=O', 'the=B-PR', 'same=I-PR', 'infection=I-PR', ',=O', 'with=O', 'lower=B-PR', 'extremity=I-PR', 'cellulitis=I-PR', 'the=O', 'likely=O', 'source=O', '.=O']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O']\n",
      "PR = [(6, 8), (11, 13)]\n",
      "TE = []\n",
      "TR = []\n",
      "A left lower extremity ultrasound was negative for deep venous thrombosis .\n",
      "['A', 'left', 'lower', 'extremity', 'ultrasound', 'was', 'negative', 'for', 'deep', 'venous', 'thrombosis', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "A left lower extremity ultrasound was negative for deep venous thrombosis .\n",
      "['B-TE', 'I-TE', 'I-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O']\n",
      "['A=B-TE', 'left=I-TE', 'lower=I-TE', 'extremity=I-TE', 'ultrasound=I-TE', 'was=O', 'negative=O', 'for=O', 'deep=B-PR', 'venous=I-PR', 'thrombosis=I-PR', '.=O']\n",
      "['B-TE', 'I-TE', 'I-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O']\n",
      "PR = [(8, 10)]\n",
      "TE = [(0, 4)]\n",
      "TR = []\n",
      "The patient was too large to have a CTA .\n",
      "['The', 'patient', 'was', 'too', 'large', 'to', 'have', 'a', 'CTA', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "The patient was too large to have a CTA .\n",
      "['O', 'O', 'O', 'B-PR', 'I-PR', 'O', 'O', 'B-TE', 'I-TE', 'O']\n",
      "['The=O', 'patient=O', 'was=O', 'too=B-PR', 'large=I-PR', 'to=O', 'have=O', 'a=B-TE', 'CTA=I-TE', '.=O']\n",
      "['O', 'O', 'O', 'B-PR', 'I-PR', 'O', 'O', 'B-TE', 'I-TE', 'O']\n",
      "PR = [(3, 4)]\n",
      "TE = [(7, 8)]\n",
      "TR = []\n",
      "Review of the medical record revealed several previous admissions for cellulitis and bacteremia . Blood cultures on this admission and were positive for Beta streptococcus Group B . The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source . A left lower extremity ultrasound was negative for deep venous thrombosis . The patient was too large to have a CTA .\n",
      "['Review', 'of', 'the', 'medical', 'record', 'revealed', 'several', 'previous', 'admissions', 'for', 'cellulitis', 'and', 'bacteremia', '.', 'Blood', 'cultures', 'on', 'this', 'admission', 'and', 'were', 'positive', 'for', 'Beta', 'streptococcus', 'Group', 'B', '.', 'The', 'patient', 'had', 'previous', 'episodes', 'of', 'the', 'same', 'infection', ',', 'with', 'lower', 'extremity', 'cellulitis', 'the', 'likely', 'source', '.', 'A', 'left', 'lower', 'extremity', 'ultrasound', 'was', 'negative', 'for', 'deep', 'venous', 'thrombosis', '.', 'The', 'patient', 'was', 'too', 'large', 'to', 'have', 'a', 'CTA', '.']\n",
      "{'B-TE', 'I-TR', 'I-PR', 'I-TE', 'B-PR', 'B-TR', 'O'}\n",
      "{0: 'B-PR', 1: 'B-TE', 2: 'B-TR', 3: 'I-PR', 4: 'I-TE', 5: 'I-TR', 6: 'O'}\n",
      "Review of the medical record revealed several previous admissions for cellulitis and bacteremia . Blood cultures on this admission and were positive for Beta streptococcus Group B . The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source . A left lower extremity ultrasound was negative for deep venous thrombosis . The patient was too large to have a CTA .\n",
      "['O', 'O', 'O', 'B-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'O', 'B-PR', 'B-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'B-PR', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'B-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TE', 'O', 'O']\n",
      "['Review=O', 'of=O', 'the=O', 'medical=B-TE', 'record=I-TE', 'revealed=O', 'several=O', 'previous=O', 'admissions=O', 'for=O', 'cellulitis=B-PR', 'and=O', 'bacteremia=B-PR', '.=B-TE', 'Blood=I-TE', 'cultures=I-TE', 'on=O', 'this=O', 'admission=O', 'and=O', 'were=O', 'positive=O', 'for=O', 'Beta=B-PR', 'streptococcus=I-PR', 'Group=I-PR', 'B=I-PR', '.=O', 'The=O', 'patient=O', 'had=O', 'previous=O', 'episodes=O', 'of=O', 'the=B-PR', 'same=I-PR', 'infection=I-PR', ',=O', 'with=B-PR', 'lower=B-PR', 'extremity=I-PR', 'cellulitis=I-PR', 'the=O', 'likely=O', 'source=O', '.=O', 'A=B-TE', 'left=I-TE', 'lower=I-TE', 'extremity=O', 'ultrasound=O', 'was=O', 'negative=O', 'for=B-PR', 'deep=I-PR', 'venous=O', 'thrombosis=O', '.=O', 'The=O', 'patient=O', 'was=O', 'too=O', 'large=O', 'to=O', 'have=O', 'a=B-TE', 'CTA=O', '.=O']\n",
      "['O', 'O', 'O', 'B-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'O', 'B-PR', 'B-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'I-PR', 'O', 'B-PR', 'B-PR', 'I-PR', 'I-PR', 'O', 'O', 'O', 'O', 'B-TE', 'I-TE', 'I-TE', 'O', 'O', 'O', 'O', 'B-PR', 'I-PR', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-TE', 'O', 'O']\n",
      "PR = [(10, 10), (12, 12), (23, 26), (34, 36), (38, 38), (39, 41), (53, 54)]\n",
      "TE = [(3, 4), (13, 15), (46, 48), (65, 65)]\n",
      "TR = []\n"
     ]
    }
   ],
   "source": [
    "instance = NLPmodule()\n",
    "\n",
    "string = \"Review of the medical record revealed several previous admissions for cellulitis and bacteremia .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)\n",
    "\n",
    "string = \"Blood cultures on this admission and were positive for Beta streptococcus Group B .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)\n",
    "\n",
    "string = \"The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)\n",
    "\n",
    "string = \"A left lower extremity ultrasound was negative for deep venous thrombosis .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)\n",
    "\n",
    "string = \"The patient was too large to have a CTA .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)\n",
    "\n",
    "string = \"Review of the medical record revealed several previous admissions for cellulitis and bacteremia . Blood cultures on this admission and were positive for Beta streptococcus Group B . The patient had previous episodes of the same infection , with lower extremity cellulitis the likely source . A left lower extremity ultrasound was negative for deep venous thrombosis . The patient was too large to have a CTA .\"\n",
    "input_list = string.split(' ')\n",
    "print(string)\n",
    "print(input_list)\n",
    "instance.get_ner_token(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ccc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
